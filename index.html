<!--
 * @Author: Jon Barron
 * @Date: 2019-05-11 22:15:22
 * @Editors: whyisyoung
 * @EditTime: 2020-10-23 10:57:25
 * @LastEditors: RMSnow xueyao_98@foxmail.com
 * @LastEditTime: 2024-02-27 23:34:11
 -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<!-- https://ibruce.info/2015/04/04/busuanzi/#more -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<html>

<head>
  <meta name=viewport content="width=device-width">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="google-site-verification" content="p7SNRHPF7y83Q-nNBLkrxFhAAosW2t40unwTxByZ0vo" />
  <meta charset="utf-8">

  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    span.tag {
      font-size: 11px;
      color: #FFFFFF;
      /* color: #07889b; */
      background-color: #0076DF;
      box-shadow: 2px 2px 1px #E0E0E0;
      padding: 1px 5px 2px 5px;
    }

    a {
      color: #1772d0;
      /* color: #07889b; */
      text-decoration: none;
    }

    a.black {
      color: #000000;
      /* color: #07889b; */
      text-decoration: none;
    }

    a:focus,
    a:hover {
      /* color: #e37222; #f09228; */
      color: rgb(180, 16, 44);
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
      /* color: #e3225c; */
      color: rgb(180, 16, 44);
      /* color: rgb(117, 15, 109); */
    }

    subheading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-style: italic;
      /* color: #e3225c; */
      color: rgb(180, 16, 44);
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: bold;
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .footer {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      opacity: 0.75;
      color: #777;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }

    span.artifact {
      color: #6cb41b;
      padding: 1px;
    }

    span.underline {
      border-bottom: 1px solid black;
      padding-bottom: 1px;
    }

    span.tldr {
      color: #555555;
    }

    em.highlight {
      color: #e37222;
    }
  </style>
  <link rel="icon" type="image/png" href="images/music.ico">
  <title>Yicheng Gu</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
    type='text/css'>
</head>

<body>
  <table width="960" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <!-- Intro Begin -->
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 22%;">
            <col span="1" style="width: 78%;">
          </colgroup>
          <tr>
            <td valign="middle">
              <img src="images/me-icassp.png" height="180px">
            </td>
            <td valign="middle">
              <p align="left">
                <name>Yicheng Gu (she / her) <img src="images/finland-pride.png" height="24px" width="29px"> <img
                    src="images/pride-old.png" height="24px" width="29px"> <img src="images/trans-pride.png"
                    height="28px">
                  </div>
                </name>
              </p>
              <p>
                Bachelor Student, <br>
                School of Data Science <br>
                The Chinese University of Hong Kong, Shenzhen
              </p>
              <p align=left>
                <!-- E-mail: <span>xueyao_98 [AT] foxmail [DOT] com</span> -->
                Email: <span>yichenggu@link.cuhk.edu.cn</span>, <span>yicheng.gu@aalto.fi</span>
                <!-- or <span class="underline">zhangxueyao19s@ict.ac.cn</span> -->
              </p>
              <p align=left>
                <a href="resume/resume_EN.pdf">Curriculum Vitae</a>
                &nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
                <a href="https://scholar.google.com/citations?user=REtoPf8AAAAJ&hl=en">Google
                  Scholar</a>
                &nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
                <a href="https://github.com/VocodexElysium"> GitHub </a>
                &nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
                <a href="https://bsky.app/profile/setykesykaa.bsky.social">Bluesky</a> &nbsp;&nbsp;&nbsp;
              </p>
            </td>
          </tr>
        </table>
        <!-- Intro End -->

        <!-- About Me -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>About me</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <tr>
            <td valign="center">
              <p>
                I'm a third-year Bachelor student at the Chinese University of Hong Kong, Shenzhen, supervised by
                Professor <a href="http://www.drwuz.com/">Zhizheng Wu</a> and working closely with <a
                  href="https://www.zhangxueyao.com/">Xueyao Zhang</a>. I am currently working as a Visiting Scholar in
                Aalto
                University with Professor <a href="https://scholar.google.co.jp/citations?user=q7-khVcAAAAJ&hl=fi">Lauri
                  Juvela</a>. <br>I'm also a co-founder of <a
                  href="https://github.com/open-mmlab/Amphion"><i>Amphion</i></a>
                <img src="https://img.shields.io/github/stars/open-mmlab/Amphion?color=success&logo=github">, which is
                an
                open-source toolkit for Audio, Music, and Speech Generation.
              </p>
              <p>
                My research interests include:
              <ul>
                <li> <b>Audio, Speech, and Music Processing</b>
                <li> <b>Differentiable Digital Signal Processing</b>
                <li> <b>Audio-Visual Generation</b>
              </ul>
              </p>
            </td>
          </tr>
        </table>
        <!-- About me End -->

        <!-- News Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Milestones</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              2025/05
            </td>
            <td valign="center">
              <a href="https://arxiv.org/abs/2505.15368">My first paper</a> about Neural Autotune got accepted by
              Interspeech 2025.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2025/05
            </td>
            <td valign="center">
              <a href="https://arxiv.org/abs/2504.04589">My first paper</a> about Virtual
              Analog Modeling got accepted by DAFx 2025.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2024/09
            </td>
            <td valign="center">
              I entered Professor <a href="https://scholar.google.co.jp/citations?user=q7-khVcAAAAJ&hl=fi">Lauri
                Juvela</a>'s lab as a Visiting Scholar in Aalto University.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2024/09
            </td>
            <td valign="center">
              <a href="https://arxiv.org/abs/2404.17161">My first journal paper</a> about neural vocoder got
              accepted
              by TASLP.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2024/09
            </td>
            <td valign="center">
              Three of my papers have been accepted by SLT 2024.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2024/07
            </td>
            <td valign="center">
              Method from my <a href="https://arxiv.org/abs/2311.14957">my first paper</a> is implemented and
              supported by <a href="https://github.com/NVIDIA/BigVGAN">NVIDIA-BigVGAN 2.0</a>
            </td>
          </tr>
          <tr>
            <td valign="center">
              2024/07
            </td>
            <td valign="center">
              My first large-scale speech dataset <a href="https://arxiv.org/abs/2407.05361">Emilia</a> got released.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2023/12
            </td>
            <td valign="center">
              <a href="https://arxiv.org/abs/2311.14957">My first paper</a> about neural vocoder got
              accepted
              by ICASSP 2024.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2023/12
            </td>
            <td valign="center">
              My first attempt at developing a
              large-scale open-source project <a href="https://github.com/open-mmlab/Amphion">Amphion</a>.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2023/10
            </td>
            <td valign="center">
              <a href="https://arxiv.org/abs/2310.11160">My first paper</a> about singing voice processing got accepted
              by ML4Audio @ NeurIPS 2023.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2022/10
            </td>
            <td valign="center">
              I entered Professor <a href="http://www.drwuz.com/">Zhizheng Wu</a>'s lab after I was admitted by The
              Chinese University of Hong Kong, Shenzhen as a Bachelor student.
            </td>
          </tr>
        </table>
        <!-- News End -->

        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <tr>
            <td>
              <div style="background-color: #F3F7FC!important;padding: 14px;">
                <p>
                  <font size="+1"><b> &#9997 &nbsp; Call for Volunteers</b></font>
                </p>
                <p>
                  <a href="https://drwuz.com/team/">Our team</a> supports trans rights and is broadly interested in
                  Transgender Voice Therapy. We are currently collabrating with local hospitals and is in need of trans
                  volunteers. If you are currently in Shenzhen or Shanghai and willing to participate our project,
                  please fill in the form <a href="images/volunteer.JPG">here</a>.
                </p>
              </div>
            </td>
          </tr>
        </table>

        <!-- Publications Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Publications</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <tr>
            <td valign="center">
              <span class="tag">TASLP</span>&nbsp;&nbsp;
              <papertitle>An Investigation of Time-Frequency Representation Discriminators for High-Fidelity Vocoder
              </papertitle>
              <br>
              <span class="underline">Yicheng
                Gu</span>, <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a class="black"
                href="https://www.colips.org/~eleliha/">Haizhou Li</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng
                Wu</a>
              <br>
              <i>IEEE Transactions on Audio, Speech and Language Processing</i>
              <br>
              <a href="https://arxiv.org/abs/2404.17161">Preprint</a> /
              <a href="https://github.com/open-mmlab/Amphion/blob/main/egs/vocoder/gan/README.md">Code</a>
              /
              <a href="https://www.yichenggu.com/TFR-Discriminators/">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose a Continuous Wavelet Transform-based Discriminator for GAN-based
                neural Vocoders.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">ICASSP 2024</span>&nbsp;&nbsp;
              <papertitle>Multi-Scale Sub-Band Constant-Q Transform Discriminator for High-Fidelity Vocoder
              </papertitle>
              <br>
              <span class="underline">Yicheng
                Gu</span>, <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a>
              <br>
              <i>International Conference on Acoustics, Speech, and Signal Processing
                2024</i>
              <br>
              <a href="https://arxiv.org/abs/2311.14957">Paper</a> /
              <a
                href="https://github.com/open-mmlab/Amphion/blob/main/egs/vocoder/gan/tfr_enhanced_hifigan/README.md">Code</a>
              /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="https://vocodexelysium.github.io/MS-SB-CQTD/">Demo</a> /
              <a href="https://huggingface.co/amphion/hifigan_speech_bigdata">Pretrained Model</a>
              <br>
              <span class="tldr">TL;DR: We propose a Constant-Q Transform-based Discriminator for GAN-based neural
                vocoders.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <!-- <span class="tag">ML4Audio @ NeurIPS 2023</span>&nbsp;&nbsp; -->
              <span class="tag">SLT 2024</span>&nbsp;&nbsp;
              <papertitle>
                Amphion: An Open-Source Audio, Music and Speech Generation Toolkit
              </papertitle>
              &nbsp;&nbsp;
              <a href="https://github.com/open-mmlab/Amphion">
                <img src="https://img.shields.io/github/stars/open-mmlab/Amphion?color=success&logo=github">
              </a>
              <br>
              <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>*, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>*, <span
                class="underline">Yicheng Gu</span>*, <a class="black"
                href="https://scholar.google.com/citations?user=60uamz4AAAAJ&hl=en&oi=sra">Yuancheng
                Wang</a>*, Haorui He, Chaoren Wang, Xi Chen, Zihao Fang, Haopeng Chen, Junan Zhang, Tze Ying Tang,
              Lexiao Zou, Mingxuan Wang, <a class="black" href="https://stevenhan1991.github.io/">Jun Han</a>, <a
                class="black" href="https://chenkai.site/">Kai
                Chen</a>, <a class="black" href="https://www.colips.org/~eleliha/">Haizhou Li</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng
                Wu</a> (*: Equal Contribution)
              <br>
              <i>IEEE Spoken Language Technology Workshop 2024</i>
              <br>
              <a href="https://arxiv.org/pdf/2312.09911.pdf">Technical Report</a> /
              <a href="https://github.com/open-mmlab/Amphion">GitHub</a> /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="https://huggingface.co/amphion">HuggingFace</a> /
              <a href="https://openxlab.org.cn/usercenter/Amphion">OpenXLab</a>
              <br>
              <span class="tldr">TL;DR: We develop a unified audio generation open-source toolkit.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">SLT 2024</span>&nbsp;&nbsp;
              <papertitle>Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech
                Generation
              </papertitle>
              <br>
              Haorui he*, Zengqiang Shang*, Chaoren Wang*, Xuyuan Li*, <span class="underline">Yicheng Gu</span>,
              Hua Hua, Liwei Liu, Chen Yang, Jiaqi Li, Peiyang Shi, Yuancheng Wang, <a class="black"
                href="https://chenkai.site/">Kai Chen</a>, Pengyuan Zhang, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a> (*: Equal Contribution)
              <br>
              <i>IEEE Spoken Language Technology Workshop 2024</i>
              <br>
              <a href="https://arxiv.org/abs/2407.05361">Preprint</a> /
              <a href="https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia">Code</a> /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="https://emilia-dataset.github.io/Emilia-Demo-Page/">Demo</a> /
              <a href="https://huggingface.co/datasets/amphion/Emilia">HuggingFace</a>
              <br>
              <span class="tldr">TL;DR: We propose a large scale multi-lingual speech dataset for TTS.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">Interspeech 2025</span>&nbsp;&nbsp;
              <papertitle>Neurodyne: Neural Pitch Manipulation with Representation Learning and Cycle-Consistency GAN
              </papertitle>
              <br>
              <i>Conference of the International Speech Communication Association 2025 </i>
              <br>
              <span class="underline">Yicheng Gu</span>, Chaoren Wang, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a>, Lauri Juvela.
              <br>
              <a href="https://arxiv.org/abs/2505.15368">Preprint</a> /
              <a href="https://github.com/open-mmlab/Amphion">Code</a> /
              <a href="https://neurodyne-demo.github.io/">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose the SOTA Neural Autotune benchmarking against Melodyne.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">DAFx 2025</span>&nbsp;&nbsp;
              <papertitle>Solid State Bus-Comp: A Large-Scale and Diverse Dataset for Dynamic Range Compressor Virtual
                Analog Modeling
              </papertitle>
              <br>
              <span class="underline">Yicheng Gu</span>, Runsong Zhang, Lauri Juvela, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a>.
              <br>
              <i>International Conference on Digital Audio Effects 2025 </i>
              <br>
              <a href="https://arxiv.org/abs/2504.04589">Preprint</a> /
              <a href="https://huggingface.co/datasets/amphion/Diff-SSL-G-Comp">HuggingFace</a> /
              <a href="https://www.yichenggu.com/DiffSSLGComp/">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose the first large-scale and diverse dataset for Virtual Analog
                Modeling.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">ML4Audio @ NeurIPS 2023</span>&nbsp;&nbsp;
              <papertitle>Leveraging Content-based Features from Multiple Acoustic Models for Singing Voice Conversion
              </papertitle>
              <br>
              <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, <span class="underline">Yicheng
                Gu</span>, Haopeng Chen, Zihao Fang, Lexiao Zou, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a>
              <br>
              <i>Machine Learning for Audio Workshop (ML4Audio) at NeurIPS 2023 </i>
              <br>
              <a href="https://arxiv.org/pdf/2310.11160.pdf">Paper</a> /
              <a href="https://github.com/open-mmlab/Amphion/tree/main/egs/svc/MultipleContentsSVC">Code</a> /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="data/MultipleContentsSVC/index.html">Demo</a> /
              <a href="https://huggingface.co/amphion/singing_voice_conversion">Pretrained Model</a> /
              <a href="https://huggingface.co/spaces/amphion/singing_voice_conversion">HuggingFace Space</a> /
              <a href="https://openxlab.org.cn/apps/detail/Amphion/singing_voice_conversion">OpenXLab App</a>
              <br>
              <span class="tldr">TL;DR: We propose to utilize multiple content features for singing voice conversion.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">SLT 2024</span>&nbsp;&nbsp;
              <papertitle>Leveraging Diverse Semantic-based Audio Pretrained Models for Singing Voice Conversion
              </papertitle>
              <br>
              <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, Zihao Fang, <span
                class="underline">Yicheng Gu</span>, Haopeng Chen, Lexiao Zou, Junan Zhang, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a>
              <br>
              <i>IEEE Spoken Language Technology Workshop 2024</i>
              <br>
              <a href="https://arxiv.org/pdf/2310.11160">Preprint</a> /
              <a href="https://github.com/open-mmlab/Amphion">Code</a> /
              <a href="https://diversesemanticsvc.github.io/">Demo</a>
              <br>
              <span class="tldr">TL;DR: We investigated the pros and cons of different semantic tokens for Singing Voice
                Conversion.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">submitted</span>&nbsp;&nbsp;
              <papertitle>FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds
              </papertitle>
              <br>
              Yiming Zhang, <span class="underline">Yicheng Gu</span>,
              <a class="black" href="https://zengyh1900.github.io/">Yanhong Zeng</a>, Zhening Xing,
              <a class="black" href="https://drwuz.com/">Zhizheng Wu</a>,
              <a class="black" href="https://chenkai.site/">Kai Chen</a>
              <br>
              <a href="https://arxiv.org/abs/2407.01494">Preprint</a> /
              <a href="https://github.com/open-mmlab/foleycrafter">Code</a> /
              <a href="https://huggingface.co/spaces/ymzhang319/FoleyCrafter">HuggingFace</a> /
              <a href="https://foleycrafter.github.io/">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose a Video-to-Audio generation pipeline with Audio-Visual
                Synchronization and Text-Editability.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">submitted</span>&nbsp;&nbsp;
              <papertitle>SingNet: Towards a Large-Scale, Diverse, and In-the-Wild Singing Voice Dataset
              </papertitle>
              <br>
              <span class="underline">Yicheng Gu</span>, Chaoren Wang, Junan Zhang, <a class="black"
                href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, Zihao Fang, Haorui He,
              <a class="black" href="https://drwuz.com/">Zhizheng Wu</a>
              <br>
              <span class="tldr">TL;DR: We propose an Extensive, Multilingual, and Diverse Singing Voice Corpus.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">submitted</span>&nbsp;&nbsp;
              <papertitle>Emilia: A Large-Scale, Extensive, Multilingual, and Diverse Dataset for Speech Generation
              </papertitle>
              <br>
              Haorui he*, Zengqiang Shang*, Chaoren Wang*, Xuyuan Li*, <span class="underline">Yicheng Gu</span>,
              Hua Hua, Liwei Liu, Chen Yang, Jiaqi Li, Peiyang Shi, Yuancheng Wang, <a class="black"
                href="https://chenkai.site/">Kai Chen</a>, Pengyuan Zhang, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a> (*: Equal Contribution)
              <br>
              <!-- <i>IEEE Spoken Language Technology Workshop 2024</i>
              <br>
              <a href="https://arxiv.org/abs/2407.05361">Preprint</a> /
              <a href="https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia">Code</a> /
              <a href="https://emilia-dataset.github.io/Emilia-Demo-Page/">Demo</a> /
              <a href="https://huggingface.co/datasets/amphion/Emilia">HuggingFace</a>
              <br> -->
              <span class="tldr">TL;DR: We propose the 2.0 version of Emilia for TTS.
              </span>
            </td>
          </tr>
        </table>
        <!-- Publications End -->

        <!-- Presentation Begin -->

        <!-- Presentation End -->

        <!-- Internship Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Professional Experiences</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              <b>Shanghai AI Laboratory</b>
            </td>
            <td>
              Research Assistant, @Shanghai, China (2023/12 ~ 2025/03)
              <br>
              <span class="tldr"><i>#Video to Audio Generation</i></span>
              <br>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              <b>Aalto Univeristy</b>
            </td>
            <td>
              Visiting Scholar, @Espoo, Finland (2024/09 ~ 2025/06)
              <br>
              <span class="tldr"><i>#Digital Audio Effects</i></span>
              <br>
            </td>
          </tr>
        </table>
        <!-- Internship End -->

        <!-- Services Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Services</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              Reviewer
            </td>
            <td>
              Conferences:
              <ul>
                <li>ICASSP 2025</li>
                <li>ICLR 2025</li>
                <li>IJCNN 2025</li>
              </ul>
              Journals:
              <ul>
                <li>IEEE Transactions on Audio, Speech and Language Processing (TASLP)</li>
                <li>IEEE Signal Processing Letters (SPL)</li>
              </ul>
            </td>
          </tr>
        </table>
        <!-- Services End -->

        <!-- Education Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              2022-2026
            </td>
            <td>
              Bachelor student in Computer Science, supervised by
              Professor <a href="http://www.drwuz.com/">Zhizheng Wu</a>
              <br>
              <span><a href="https://sds.cuhk.edu.cn/en">School of Data Science</a>, <a
                  href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen, China
                </a></span>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              2024-2025
            </td>
            <td>
              Exchange student in Computer Science, supervised by
              Professor <a href="https://scholar.google.co.jp/citations?user=q7-khVcAAAAJ&hl=fi">Lauri Juvela</a>
              <br>
              <span><a href="https://www.aalto.fi/en/school-of-science">School of Science</a>, <a
                  href="https://www.aalto.fi/en">Aalto University, Espoo, Finland
                </a></span>
            </td>
          </tr>
        </table>
        <!-- Education End -->

        <!-- Awards Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Honors and Awards</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              2024
            </td>
            <td>
              The Nobel Class (Top 1, 2024)
            </td>
          </tr>
          <tr>
            <td valign="center">
              2024
            </td>
            <td>
              The Academic Performance Scholarship, Class A (Top 1%, 2024)
            </td>
          </tr>
          <tr>
            <td valign="center">
              2023
            </td>
            <td>
              The Academic Performance Scholarship, Class B (Top 3%, 2023)
            </td>
          </tr>
          <tr>
            <td valign="center">
              2022
            </td>
            <td>
              "LanHuaYing" Scholarship (Top 10 admitted students in Zhejiang Province, 2022)
            </td>
          </tr>
        </table>
        <!-- Awards End -->

        <!-- Blog Begin -->

        <!-- Blog End -->

        <!-- Friends Begin -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Friendly Links</heading>
            </td>
          </tr>
        </table>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="http://www.liziniu.org/">Ziniu Li (李子牛)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="http://www.lamda.nju.edu.cn/xuek/">Ke Xue (薛轲)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://kyonhuang.top/">Siteng Huang (黄思腾)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://hellogod.cn/">一时博客 (曹真)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;
        <a href="https://sheng-qiang.github.io/">Qiang Sheng (盛强)</a> -->
        <!-- Friends End -->

        <!-- Other Sites Begin -->

        <!-- Other Sites End -->

        <table width="100%" align="center" border="0" cellpadding="12">
          <tr>
            <td width="100%" valign="center">
              <p class="footer">
                Design: <a href="https://jonbarron.info/" style="color: #777; font-size: 14px;">Jon
                  Barron</a>, <a href="https://liminyang.web.illinois.edu/  "
                  style="color: #777; font-size: 14px;">Limin Yang</a>, <a href="https://sheng-qiang.github.io/"
                  style="color: #777; font-size: 14px;">Qiang Sheng</a>, and <a href="https://www.zhangxueyao.com/"
                  style="color: #777; font-size: 14px;">Xueyao
                  Zhang</a>.<br>
                Last updated:
                <script>
                  t = new Date(document.lastModified).toLocaleDateString()
                  document.write(t);
                </script>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <span id="busuanzi_container_site_pv">#Views: <span id="busuanzi_value_site_pv"></span>, #Visitors:
                  <span id="busuanzi_value_site_uv"></span></span> (2024/04/10~)
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>