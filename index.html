<!--
 * @Author: Jon Barron
 * @Date: 2019-05-11 22:15:22
 * @Editors: whyisyoung
 * @EditTime: 2020-10-23 10:57:25
 * @LastEditors: RMSnow xueyao_98@foxmail.com
 * @LastEditTime: 2024-02-27 23:34:11
 -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<!-- https://ibruce.info/2015/04/04/busuanzi/#more -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<html>

<head>
  <meta name=viewport content="width=device-width">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="google-site-verification" content="p7SNRHPF7y83Q-nNBLkrxFhAAosW2t40unwTxByZ0vo" />
  <meta charset="utf-8">

  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    span.tag {
      font-size: 11px;
      color: #FFFFFF;
      /* color: #07889b; */
      background-color: #0076DF;
      box-shadow: 2px 2px 1px #E0E0E0;
      padding: 1px 5px 2px 5px;
    }

    a {
      color: #1772d0;
      /* color: #07889b; */
      text-decoration: none;
    }

    a.black {
      color: #000000;
      /* color: #07889b; */
      text-decoration: none;
    }

    a:focus,
    a:hover {
      /* color: #e37222; #f09228; */
      color: rgb(180, 16, 44);
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
      /* color: #e3225c; */
      color: rgb(180, 16, 44);
      /* color: rgb(117, 15, 109); */
    }

    subheading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-style: italic;
      /* color: #e3225c; */
      color: rgb(180, 16, 44);
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: bold;
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .footer {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      opacity: 0.75;
      color: #777;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }

    span.artifact {
      color: #6cb41b;
      padding: 1px;
    }

    span.underline {
      border-bottom: 1px solid black;
      padding-bottom: 1px;
    }

    span.tldr {
      color: #555555;
    }

    em.highlight {
      color: #e37222;
    }
  </style>
  <link rel="icon" type="image/png" href="images/music.ico">
  <title>Yicheng Gu</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
    type='text/css'>
</head>

<body>
  <table width="960" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <!-- Intro Begin -->
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 22%;">
            <col span="1" style="width: 78%;">
          </colgroup>
          <tr>
            <td valign="middle">
              <img src="images/me-icassp.png" height="180px">
            </td>
            <td valign="middle">
              <p align="left">
                <name>Yicheng Gu (she / her) <img src="images/trans-pride.png" height="28px"></div>
                </name>
              </p>
              <p>
                Bachelor Student, <br>
                School of Data Science <br>
                The Chinese University of Hong Kong, Shenzhen
              </p>
              <p align=left>
                <!-- E-mail: <span>xueyao_98 [AT] foxmail [DOT] com</span> -->
                Email: <span>yichenggu@link.cuhk.edu.cn</span>
                <!-- or <span class="underline">zhangxueyao19s@ict.ac.cn</span> -->
              </p>
              <p align=left>
                <a href="resume/resume_EN.pdf">Curriculum Vitae</a>
                &nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
                <a href="https://scholar.google.com/citations?user=REtoPf8AAAAJ&hl=en">Google
                  Scholar</a>
                &nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
                <a href="https://github.com/VocodexElysium"> GitHub </a>
                <!-- &nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp; -->
                <!-- <a href="https://weibo.com/u/5831484448">Weibo</a> &nbsp;&nbsp;&nbsp; -->
              </p>
            </td>
          </tr>
        </table>
        <!-- Intro End -->

        <!-- About Me -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>About me</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <tr>
            <td valign="center">
              <p>
                I'm a second-year Bachelor student at the Chinese University of Hong Kong, Shenzhen,
                supervised by
                Professor <a href="http://www.drwuz.com/">Zhizheng Wu</a> and working closely with <a
                  href="https://www.zhangxueyao.com/">Xueyao Zhang</a>. My ongoing
                works focus on <i>Neural Vocoder</i> and <i> Differentiable Digital Signal Processing</i>
                (DDSP). Recently, I'm participating in the development of the prototype of the
                open-source <a href="https://github.com/open-mmlab/Amphion"><i>Amphion</i></a> toolkit as one of the
                core numbers.
              </p>
              <p>
                My research interests include:
              <ul>
                <li> <b>Neural Vocoder</b>
                <li> <b>Differentiable Digital Signal Processing</b>
                <li> <b>Music Data Scaling Up</b>
                <li> <b>Audio-Visual Generation</b>
              </ul>
              </p>
            </td>
          </tr>
        </table>
        <!-- About me End -->

        <!-- News Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Milestones</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              2023/12
            </td>
            <td valign="center">
              <a href="https://arxiv.org/abs/2311.14957">My first paper</a> about neural vocoder got
              accepted
              by ICASSP 2024.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2023/11
            </td>
            <td valign="center">
              <a href="https://github.com/open-mmlab/Amphion">My first attempt</a> at being a core member in
              the development of a
              large-scale open-source project.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2023/10
            </td>
            <td valign="center">
              <a href="https://arxiv.org/abs/2310.11160">My first paper</a> about singing voice processing got accepted
              by ML4Audio @ NeurIPS 2023.
            </td>
          </tr>
          <tr>
            <td valign="center">
              2022/10
            </td>
            <td valign="center">
              I entered Professor <a href="http://www.drwuz.com/">Zhizheng Wu</a>'s lab after I was admitted by The
              Chinese University of Hong Kong, Shenzhen as a Bachelor student.
            </td>
          </tr>
        </table>
        <!-- News End -->

        <!-- Publications Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Publications</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <tr>
            <td valign="center">
              <span class="tag">ICASSP 2024</span>&nbsp;&nbsp;
              <papertitle>Multi-Scale Sub-Band Constant-Q Transform Discriminator for High-Fidelity Vocoder
              </papertitle>
              <br>
              <span class="underline">Yicheng
                Gu</span>, <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a>
              <br>
              <i>International Conference on Acoustics, Speech, and Signal Processing
                2024</i>
              <br>
              <a href="https://arxiv.org/abs/2311.14957">Paper</a> /
              <a
                href="https://github.com/open-mmlab/Amphion/blob/main/egs/vocoder/gan/tfr_enhanced_hifigan/README.md">Code</a>
              /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="https://vocodexelysium.github.io/MS-SB-CQTD/">Demo</a> /
              <a href="https://huggingface.co/amphion/hifigan_speech_bigdata">Pretrained Model</a>
              <br>
              <span class="tldr">TL;DR: We propose a Constant-Q Transform-based Discriminator for GAN-based neural
                vocoders.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <!-- <span class="tag">ML4Audio @ NeurIPS 2023</span>&nbsp;&nbsp; -->
              <a href="https://github.com/open-mmlab/Amphion">
                <img src="https://img.shields.io/github/stars/open-mmlab/Amphion?color=success&logo=github">
              </a>
              &nbsp;&nbsp;
              <papertitle>
                Amphion: An Open-Source Audio, Music and Speech Generation Toolkit
              </papertitle>
              <br>
              <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>*, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>*, <span
                class="underline">Yicheng Gu</span>*, <a class="black"
                href="https://scholar.google.com/citations?user=60uamz4AAAAJ&hl=en&oi=sra">Yuancheng
                Wang</a>*, Haorui He, Chaoren Wang, Xi Chen, Zihao Fang, Haopeng Chen, Junan Zhang, Tze Ying Tang,
              Lexiao Zou, Mingxuan Wang, <a class="black" href="https://stevenhan1991.github.io/">Jun Han</a>, <a
                class="black" href="https://chenkai.site/">Kai
                Chen</a>, <a class="black" href="https://www.colips.org/~eleliha/">Haizhou Li</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng
                Wu</a> (*: Equal Contribution)
              <br>
              <!-- <i>Machine Learning for Audio Workshop (ML4Audio) at NeurIPS 2023 </i> -->
              <!-- <br> -->
              <a href="https://arxiv.org/pdf/2312.09911.pdf">Technical Report</a> /
              <a href="https://github.com/open-mmlab/Amphion">GitHub</a> /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="https://huggingface.co/amphion">HuggingFace</a> /
              <a href="https://openxlab.org.cn/usercenter/Amphion">OpenXLab</a>
              <br>
              <span class="tldr">TL;DR: We develop a unified audio generation open-source toolkit.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">ML4Audio @ NeurIPS 2023</span>&nbsp;&nbsp;
              <papertitle>Leveraging Content-based Features from Multiple Acoustic Models for Singing Voice Conversion
              </papertitle>
              <br>
              <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, <span class="underline">Yicheng
                Gu</span>, Haopeng Chen, Zihao Fang, Lexiao Zou, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a>
              <br>
              <i>Machine Learning for Audio Workshop (ML4Audio) at NeurIPS 2023 </i>
              <br>
              <a href="https://arxiv.org/pdf/2310.11160.pdf">Paper</a> /
              <a href="https://github.com/open-mmlab/Amphion/tree/main/egs/svc/MultipleContentsSVC">Code</a> /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="data/MultipleContentsSVC/index.html">Demo</a> /
              <a href="https://huggingface.co/amphion/singing_voice_conversion">Pretrained Model</a> /
              <a href="https://huggingface.co/spaces/amphion/singing_voice_conversion">HuggingFace Space</a> /
              <a href="https://openxlab.org.cn/apps/detail/Amphion/singing_voice_conversion">OpenXLab App</a>
              <br>
              <span class="tldr">TL;DR: We propose to utilize multiple content features for singing voice conversion.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">submitted</span>&nbsp;&nbsp;
              <papertitle>An Investigation of Time-Frequency Representation Discriminators for High-Fidelity Vocoder
              </papertitle>
              <br>
              <span class="underline">Yicheng
                Gu</span>, <a class="black" href="https://www.zhangxueyao.com/">Xueyao Zhang</a>, <a class="black"
                href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a class="black"
                href="https://www.colips.org/~eleliha/">Haizhou Li</a>, <a class="black"
                href="https://drwuz.com/">Zhizheng
                Wu</a>
              <br>
              <a href="https://arxiv.org/abs/2404.17161">Preprint</a> /
              <a href="https://github.com/open-mmlab/Amphion/blob/main/egs/vocoder/gan/README.md">Code</a>
              /
              <a href="https://www.yichenggu.com/TFR-Discriminators/">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose a Continuous Wavelet Transform-based Discriminator for GAN-based
                neural Vocoders.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">submitted</span>&nbsp;&nbsp;
              <papertitle>FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds
              </papertitle>
              <br>
              Yiming Zhang, <span class="underline">Yicheng Gu</span>,
              <a class="black" href="https://zengyh1900.github.io/">Yanhong Zeng</a>, Zhening Xing,
              <a class="black" href="https://drwuz.com/">Zhizheng Wu</a>,
              <a class="black" href="https://chenkai.site/">Kai Chen</a>
              <br>
              <a href="https://arxiv.org/abs/2407.01494">Preprint</a> /
              <a href="https://github.com/open-mmlab/foleycrafter">Code</a> /
              <a href="https://huggingface.co/spaces/ymzhang319/FoleyCrafter">HuggingFace</a> /
              <a href="https://foleycrafter.github.io/">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose a Video-to-Audio generation pipeline with Audio-Visual
                Synchronization and Text-Editability.
              </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">submitted</span>&nbsp;&nbsp;
              <papertitle>Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech
                Generation
              </papertitle>
              <br>
              Haorui he*, Zengqiang Shang*, Chaoren Wang*, Xuyuan Li*, <span class="underline">Yicheng Gu</span>,
              Hua Hua, Liwei Liu, Chen Yang, Jiaqi Li, Peiyang Shi, Yuancheng Wang, <a class="black"
                href="https://chenkai.site/">Kai Chen</a>, Pengyuan Zhang, <a class="black"
                href="https://drwuz.com/">Zhizheng Wu</a> (*: Equal Contribution)
              <br>
              <a href="https://arxiv.org/abs/2407.05361">Preprint</a> /
              <a href="https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia">Code</a> /
              <!-- <a href="data/HAT/slides.pdf">Slides</a> / -->
              <a href="https://emilia-dataset.github.io/Emilia-Demo-Page/">Demo</a> /
              <a href="https://huggingface.co/datasets/amphion/Emilia">HuggingFace</a>
              <br>
              <span class="tldr">TL;DR: We propose a large scale multi-lingual speech dataset for TTS.
              </span>
            </td>
          </tr>
        </table>
        <!-- Publications End -->

        <!-- Presentation Begin -->

        <!-- Presentation End -->

        <!-- Internship Begin -->

        <!-- Internship End -->

        <!-- Services Begin -->

        <!-- Services End -->

        <!-- Education Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              2022-
            </td>
            <td>
              Bachelor student in Computer Science, supervised by
              Professor <a href="http://www.drwuz.com/">Zhizheng Wu</a>
              <br>
              <span><a href="https://sds.cuhk.edu.cn/en">School of Data Science (SDS)</a>, <a
                  href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen
                </a></span>
            </td>
          </tr>
        </table>
        <!-- Education End -->

        <!-- Awards Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Honors and Awards</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <colgroup>
            <col span="1" style="width: 23%;">
            <col span="1" style="width: 77%;">
          </colgroup>
          <tr>
            <td valign="center">
              2023
            </td>
            <td>
              The Academic Performance Scholarship, Class B (Top 3%, 2023)
            </td>
          </tr>
          <tr>
            <td valign="center">
              2022
            </td>
            <td>
              "LanHuaYing" Scholarship (Top 10 admitted students in Zhejiang Province, 2022)
            </td>
          </tr>
        </table>
        <!-- Awards End -->

        <!-- Blog Begin -->

        <!-- Blog End -->

        <!-- Friends Begin -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Friendly Links</heading>
            </td>
          </tr>
        </table>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="http://www.liziniu.org/">Ziniu Li (李子牛)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="http://www.lamda.nju.edu.cn/xuek/">Ke Xue (薛轲)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://kyonhuang.top/">Siteng Huang (黄思腾)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://hellogod.cn/">一时博客 (曹真)</a>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        &nbsp;&nbsp;&nbsp;
        <a href="https://sheng-qiang.github.io/">Qiang Sheng (盛强)</a> -->
        <!-- Friends End -->

        <!-- Other Sites Begin -->

        <!-- Other Sites End -->

        <table width="100%" align="center" border="0" cellpadding="12">
          <tr>
            <td width="100%" valign="center">
              <p class="footer">
                Design: <a href="https://jonbarron.info/" style="color: #777; font-size: 14px;">Jon
                  Barron</a>, <a href="https://liminyang.web.illinois.edu/  "
                  style="color: #777; font-size: 14px;">Limin Yang</a>, <a href="https://sheng-qiang.github.io/"
                  style="color: #777; font-size: 14px;">Qiang Sheng</a>, and <a href="https://www.zhangxueyao.com/"
                  style="color: #777; font-size: 14px;">Xueyao
                  Zhang</a>.<br>
                Last updated:
                <script>
                  t = new Date(document.lastModified).toLocaleDateString()
                  document.write(t);
                </script>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <span id="busuanzi_container_site_pv">#Views: <span id="busuanzi_value_site_pv"></span>, #Visitors:
                  <span id="busuanzi_value_site_uv"></span></span> (2021/8/1~)
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>